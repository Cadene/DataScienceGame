{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSG: MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arda/Documents/youtube\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline, make_union\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cross_validation import cross_val_score, train_test_split,StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lib_DSG import ColumnSelector, DenseTransformer\n",
    "\n",
    "\n",
    "folder = os.getcwd() ; print folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd_train = pd.read_csv('./data/train_sample_munged.csv', header=0, escapechar='\\\\', quotechar='\"', low_memory=False)\n",
    "pd_test = pd.read_csv('./data/test_sample_munged.csv', header=0, escapechar='\\\\', quotechar='\"', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd_train = pd_train.fillna('')\n",
    "pd_test = pd_test.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'video_category_id', u'title', u'description', u'published_at',\n",
      "       u'viewCount', u'likeCount', u'dislikeCount', u'favoriteCount',\n",
      "       u'commentCount', u'duration', u'dimension', u'definition', u'caption',\n",
      "       u'licensedContent', u'topicIds', u'relevantTopicIds', u'dimension_2d',\n",
      "       u'dimension_3d', u'definition_hd', u'definition_sd'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print pd_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a =pd_train['topicIds'].apply(lambda r: \"\".join(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dico_pattern={'match_lowercase_only':'\\\\b[a-z]+\\\\b',\n",
    "              'match_word':'\\\\w{1,}',\n",
    "              'match_word1': '(?u)\\\\b\\\\w+\\\\b',\n",
    "              'match_word_punct': '\\w+|[,.?!;]',\n",
    "              'match_NNP': '\\\\b[A-Z][a-z]+\\\\b|\\\\b[A-Z]+\\\\b',\n",
    "              'match_punct': \"[,.?!;'-]\"\n",
    "             }\n",
    "tfv_title = TfidfVectorizer(lowercase=True, stop_words='english', token_pattern=dico_pattern[\"match_word1\"], \n",
    "                      ngram_range=(1, 2), max_df=1.0, min_df=2, max_features=None, \n",
    "                      vocabulary=None, binary=True, norm=u'l2', \n",
    "                      use_idf=True, smooth_idf=True, sublinear_tf=True)\n",
    "\n",
    "tfv_desc = TfidfVectorizer(lowercase=True, stop_words='english', token_pattern=dico_pattern[\"match_word1\"], \n",
    "                      ngram_range=(1, 2), max_df=1.0, min_df=2, max_features=None, \n",
    "                      vocabulary=None, binary=True, norm=u'l2', \n",
    "                      use_idf=True, smooth_idf=True, sublinear_tf=True)\n",
    "\n",
    "clf = MultinomialNB(alpha=0.05, fit_prior=True, class_prior=None)\n",
    "\n",
    "title_pipe = make_pipeline(ColumnSelector(key='title'), tfv_title)\n",
    "\n",
    "desc_pipe = make_pipeline(ColumnSelector(key='description'), tfv_desc)\n",
    "\n",
    "pipeline = make_union(title_pipe, desc_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(239225, 594406)\n"
     ]
    }
   ],
   "source": [
    "Y = pd_train[u'video_category_id'].values\n",
    "X = pipeline.fit_transform(pd_train) ; print X.shape\n",
    "X_test = pipeline.transform(pd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01  0.04  0.07  0.1   0.13  0.16  0.19]\n"
     ]
    }
   ],
   "source": [
    "alphas = np.arange(0.01, 0.2, 0.03)\n",
    "#alphas = [0.06]\n",
    "print alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSS: acc: 0.7568, std: 0.0014, alpha: 0.01\n",
      "SSS: acc: 0.7588, std: 0.0016, alpha: 0.04\n",
      "SSS: acc: 0.7586, std: 0.0015, alpha: 0.07\n",
      "SSS: acc: 0.7575, std: 0.0017, alpha: 0.1\n",
      "SSS: acc: 0.7564, std: 0.0016, alpha: 0.13\n",
      "SSS: acc: 0.7551, std: 0.0016, alpha: 0.16\n",
      "SSS: acc: 0.7536, std: 0.0016, alpha: 0.19\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "for i in alphas:\n",
    "    clf.alpha = i\n",
    "\n",
    "    sss = StratifiedShuffleSplit(Y, 10, test_size=0.2, random_state=0)\n",
    "    scores_sss = cross_val_score(clf, X, Y,scoring='accuracy',cv=sss, n_jobs=-1)\n",
    "\n",
    "    print (\"SSS: acc: %0.4f, std: %0.4f, alpha: %s\" %(scores_sss.mean(), scores_sss.std(), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (28723, 77821)\n"
     ]
    }
   ],
   "source": [
    "Y = pd_train['Author'].values\n",
    "X = pipeline.fit_transform(pd_train)\n",
    "X_test = pipeline.transform(pd_test)\n",
    "\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "SLF: acc: 0.8202, std: 0.0084, SSS: acc: 0.8181, std: 0.0058, alpha: 0.01\n",
      "SLF: acc: 0.8267, std: 0.0064, SSS: acc: 0.8246, std: 0.0054, alpha: 0.04\n",
      "SLF: acc: 0.8277, std: 0.0064, SSS: acc: 0.8242, std: 0.0053, alpha: 0.07\n",
      "SLF: acc: 0.8251, std: 0.0116, SSS: acc: 0.8231, std: 0.0048, alpha: 0.1\n",
      "SLF: acc: 0.8263, std: 0.0063, SSS: acc: 0.8216, std: 0.0043, alpha: 0.13\n",
      "SLF: acc: 0.8244, std: 0.0041, SSS: acc: 0.8196, std: 0.0047, alpha: 0.16\n",
      "SLF: acc: 0.8233, std: 0.0051, SSS: acc: 0.8178, std: 0.0047, alpha: 0.19\n"
     ]
    }
   ],
   "source": [
    "for weight in weights:\n",
    "    print weight\n",
    "    \n",
    "    pipeline.transformer_weights=[1.3, 1, 1.1, 1]\n",
    "    \n",
    "    tfv_uni.binary=True\n",
    "    tfv_bi.binary=True\n",
    "    tfv_nnp.binary=True\n",
    "    tfv_punctuation.binary=True\n",
    "    \n",
    "    X = pipeline.fit_transform(pd_train)\n",
    "    results=[]\n",
    "    for i in alphas:\n",
    "        clf.alpha = i\n",
    "        \n",
    "        skf = StratifiedKFold(Y, n_folds=10, indices=None, shuffle=True, random_state=None)\n",
    "        scores_skf = cross_val_score(clf, X, Y,scoring='accuracy',cv=skf, n_jobs=-1)\n",
    "        \n",
    "        sss = StratifiedShuffleSplit(Y, 10, test_size=0.2, random_state=0)\n",
    "        scores_sss = cross_val_score(clf, X, Y,scoring='accuracy',cv=sss, n_jobs=-1)\n",
    "\n",
    "        print (\"SLF: acc: %0.4f, std: %0.4f, SSS: acc: %0.4f, std: %0.4f, alpha: %s\" %\n",
    "               (scores_skf.mean(), scores_skf.std(), scores_sss.mean(), scores_sss.std(), i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SUBMIT KAGGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = NB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(index=None)\n",
    "submit['Id']=pd_test['Id']\n",
    "submit['Pred']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit.to_csv(folder+'/results/0.arda1.csv',sep=';',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# FINAL DUMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_pipe = make_pipeline(pipeline, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_pipe.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
