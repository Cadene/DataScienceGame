{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSG: MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dico_pattern={'match_lowercase_only':'\\\\b[a-z]+\\\\b',\n",
    "              'match_word':'\\\\w{1,}',\n",
    "              'match_word1': '(?u)\\\\b\\\\w+\\\\b',\n",
    "              'match_word_punct': '\\w+|[,.?!;]',\n",
    "              'match_NNP': '\\\\b[A-Z][a-z]+\\\\b|\\\\b[A-Z]+\\\\b',\n",
    "              'match_punct': \"[,.?!;'-]\"\n",
    "             }\n",
    "\n",
    "tfv_uni = TfidfVectorizer(lowercase=False, analyzer=u'word', stop_words=None, token_pattern=dico_pattern[\"match_lowercase_only\"],\n",
    "                ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, vocabulary=None,\n",
    "                binary=True, norm=u'l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
    "\n",
    "tfv_bi = TfidfVectorizer(lowercase=False, analyzer=u'word', stop_words=None, token_pattern=dico_pattern[\"match_word1\"],\n",
    "                ngram_range=(2, 2), max_df=1.0, min_df=2, max_features=None, vocabulary=None,\n",
    "                binary=True, norm=u'l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
    "\n",
    "tfv_nnp = TfidfVectorizer(lowercase=False, analyzer=u'word', stop_words=None, token_pattern=dico_pattern[\"match_NNP\"],\n",
    "                ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, vocabulary=None,\n",
    "                binary=True, norm=u'l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
    "\n",
    "tfv_punctuation = TfidfVectorizer(lowercase=False, analyzer=u'word', stop_words=None, token_pattern=dico_pattern[\"match_punct\"],\n",
    "                ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, vocabulary=None,\n",
    "                binary=True, norm=u'l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
    "\n",
    "clf = MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)\n",
    "\n",
    "uni = make_pipeline(ColumnSelector(key='Sentence'), tfv_uni)\n",
    "bi = make_pipeline(ColumnSelector(key='Sentence'), tfv_bi)\n",
    "nnp = make_pipeline(ColumnSelector(key='Sentence'), tfv_nnp)\n",
    "punctuation = make_pipeline(ColumnSelector(key='Sentence'), tfv_punctuation)\n",
    "\n",
    "\n",
    "pipeline = make_union(uni, bi, nnp, punctuation)\n",
    "pipeline.transformer_weights=[1.3, 1, 1.1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (28723, 77821)\n"
     ]
    }
   ],
   "source": [
    "Y = pd_train['Author'].values\n",
    "X = pipeline.fit_transform(pd_train)\n",
    "X_test = pipeline.transform(pd_test)\n",
    "\n",
    "print X.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
