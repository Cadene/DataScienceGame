{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building model based on SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arda/Documents/DSG\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#feature extraction modules\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, SparsePCA, PCA\n",
    "from sklearn.svm import LinearSVC, LinearSVR, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cross_validation import cross_val_score, train_test_split,StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, make_union\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from lib_DSG import ColumnSelector, DenseTransformer\n",
    "\n",
    "\n",
    "#confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "folder = os.getcwd() ; print folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd_train = pd.io.pickle.read_pickle(folder + '/data_munged/pd_train_tagged')\n",
    "#pd_test = pd.io.pickle.read_pickle(folder + '/data_munged/pd_test_tagged')\n",
    "\n",
    "pd_train = pd.io.pickle.read_pickle(folder + '/data_munged/pd_train_munged')\n",
    "pd_test = pd.io.pickle.read_pickle(folder + '/data_munged/pd_test_munged')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dico_pattern={'match_lowercase_only':'\\\\b[a-z]+\\\\b',\n",
    "              'match_word':'\\\\w{1,}',\n",
    "              'match_word1': '(?u)\\\\b\\\\w+\\\\b',\n",
    "              'match_word_punct': '\\w+|[,.?!;]',\n",
    "              'match_NNP': '\\\\b[A-Z][a-z]+\\\\b|\\\\b[A-Z]+\\\\b',\n",
    "              'match_punct': \"[,.?!;'-]\"\n",
    "             }\n",
    "tfv = TfidfVectorizer(lowercase=False, stop_words=None, token_pattern=dico_pattern[\"match_word_punct\"], \n",
    "                      ngram_range=(1, 2), max_df=1.0, min_df=2, max_features=None, \n",
    "                      vocabulary=None, binary=True, norm=u'l2', \n",
    "                      use_idf=True, smooth_idf=True, sublinear_tf=True)\n",
    "\n",
    "clf = LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001,\n",
    "          C=1.0, multi_class='ovr', fit_intercept=True,\n",
    "          intercept_scaling=1, class_weight=None, verbose=0,\n",
    "          random_state=None, max_iter=1000)\n",
    "\n",
    "pipeline = make_pipeline(ColumnSelector(key='Sentence'), tfv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28723, 70877)\n"
     ]
    }
   ],
   "source": [
    "Y = pd_train['Author'].values\n",
    "X = pipeline.fit_transform(pd_train) ; print X.shape\n",
    "X_test = pipeline.transform(pd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1  0.3  0.5  0.7  0.9  1.1]\n"
     ]
    }
   ],
   "source": [
    "alphas = np.arange(0.1, 1.2, 0.2)\n",
    "print alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLF: acc: 0.7820, std: 0.0052, SSS: acc: 0.7798, std: 0.0039, alpha: 0.1\n",
      "SLF: acc: 0.8110, std: 0.0082, SSS: acc: 0.8044, std: 0.0052, alpha: 0.3\n",
      "SLF: acc: 0.8121, std: 0.0038, SSS: acc: 0.8087, std: 0.0046, alpha: 0.5\n",
      "SLF: acc: 0.8138, std: 0.0060, SSS: acc: 0.8094, std: 0.0044, alpha: 0.7\n",
      "SLF: acc: 0.8138, std: 0.0063, SSS: acc: 0.8086, std: 0.0043, alpha: 0.9\n",
      "SLF: acc: 0.8146, std: 0.0068, SSS: acc: 0.8079, std: 0.0040, alpha: 1.1\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "for i in alphas:\n",
    "    clf.C = i\n",
    "    \n",
    "    skf = StratifiedKFold(Y, n_folds=10, indices=None, shuffle=True, random_state=None)\n",
    "    scores_skf = cross_val_score(clf, X, Y,scoring='accuracy',cv=skf, n_jobs=-1)\n",
    "\n",
    "    sss = StratifiedShuffleSplit(Y, 10, test_size=0.2, random_state=0)\n",
    "    scores_sss = cross_val_score(clf, X, Y,scoring='accuracy',cv=sss, n_jobs=-1)\n",
    "\n",
    "    print (\"SLF: acc: %0.4f, std: %0.4f, SSS: acc: %0.4f, std: %0.4f, alpha: %s\" %\n",
    "           (scores_skf.mean(), scores_skf.std(), scores_sss.mean(), scores_sss.std(), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8070 (+/- 0.0070)\n",
      "Accuracy: 0.8062 (+/- 0.0099)\n",
      "Accuracy: 0.8111 (+/- 0.0102)\n",
      "Accuracy: 0.8074 (+/- 0.0107)\n",
      "Accuracy: 0.8051 (+/- 0.0103)\n",
      "['austen' 'doyle' 'poe' 'shakespeare' 'twain' 'wilde']\n",
      "[[8558  367   31   57  215  559]\n",
      " [ 459 4121   80   62  375  508]\n",
      " [  13   31   89    5    9   13]\n",
      " [  85   60   14 1937  136   71]\n",
      " [ 220  412   17   87 5024  312]\n",
      " [ 611  497   12   44  236 3398]]\n"
     ]
    }
   ],
   "source": [
    "clf.C = 0.7\n",
    "\n",
    "for i in range(5):\n",
    "    scores=[]\n",
    "    confusion_mat = np.zeros([6,6],dtype=int)\n",
    "    for cv in range(5):\n",
    "        x_train, x_val, y_train, y_val = train_test_split(X,Y, test_size=0.2)\n",
    "\n",
    "        clf.fit(x_train,y_train)\n",
    "\n",
    "        scores.append(clf.score(x_val,y_val))\n",
    "        confusion_mat+=confusion_matrix(clf.predict(x_val),y_val)\n",
    "    print (\"Accuracy: %0.4f (+/- %0.4f)\" % (np.mean(scores), np.std(scores) * 2))\n",
    "        \n",
    "print clf.classes_\n",
    "print confusion_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dico_pattern={'match_lowercase_only':'\\\\b[a-z]+\\\\b',\n",
    "              'match_word':'\\\\w{1,}',\n",
    "              'match_word1': '(?u)\\\\b\\\\w+\\\\b',\n",
    "              'match_word_punct': '\\w+|[,.?!;]',\n",
    "              'match_NNP': '\\\\b[A-Z][a-z]+\\\\b|\\\\b[A-Z]+\\\\b',\n",
    "              'match_punct': \"[,.?!;'-]\"\n",
    "             }\n",
    "\n",
    "tfv_uni = TfidfVectorizer(lowercase=False, analyzer=u'word', stop_words=None, token_pattern=dico_pattern[\"match_lowercase_only\"],\n",
    "                ngram_range=(1, 1), max_df=1.0, min_df=2, max_features=None, vocabulary=None,\n",
    "                binary=True, norm=u'l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
    "\n",
    "tfv_bi = TfidfVectorizer(lowercase=False, analyzer=u'word', stop_words=None, token_pattern=dico_pattern[\"match_word1\"],\n",
    "                ngram_range=(2, 2), max_df=1.0, min_df=2, max_features=None, vocabulary=None,\n",
    "                binary=True, norm=u'l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
    "\n",
    "tfv_nnp = TfidfVectorizer(lowercase=False, analyzer=u'word', stop_words=None, token_pattern=dico_pattern[\"match_NNP\"],\n",
    "                ngram_range=(1, 1), max_df=1.0, min_df=2, max_features=None, vocabulary=None,\n",
    "                binary=True, norm=u'l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
    "\n",
    "tfv_punctuation = TfidfVectorizer(lowercase=False, analyzer=u'word', stop_words=None, token_pattern=dico_pattern[\"match_punct\"],\n",
    "                ngram_range=(1, 1), max_df=1.0, min_df=2, max_features=None, vocabulary=None,\n",
    "                binary=True, norm=u'l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
    "\n",
    "clf = LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, C=1.0, multi_class='ovr',\n",
    "          fit_intercept=True, intercept_scaling=1, class_weight=None, verbose=0,\n",
    "          random_state=None, max_iter=1000)\n",
    "\n",
    "uni = make_pipeline(ColumnSelector(key='Sentence'), tfv_uni)\n",
    "bi = make_pipeline(ColumnSelector(key='Sentence'), tfv_bi)\n",
    "nnp = make_pipeline(ColumnSelector(key='Sentence'), tfv_nnp)\n",
    "punctuation = make_pipeline(ColumnSelector(key='Sentence'), tfv_punctuation)\n",
    "\n",
    "new_features = pd_train.columns[10:13]\n",
    "new_features = make_pipeline(ColumnSelector(key=new_features))\n",
    "\n",
    "pipeline = make_union(uni, bi, nnp, punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columnselector', ColumnSelector(key=Index([u'nb_'', u'nb_all', u'nb_,;'], dtype='object')))])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28723, 66630)\n"
     ]
    }
   ],
   "source": [
    "Y = pd_train['Author'].values\n",
    "X = pipeline.fit_transform(pd_train)\n",
    "X_test = pipeline.transform(pd_test)\n",
    "\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf, X,Y,scoring='accuracy', cv=5) ; print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.78775226,  0.79324748,  0.75766017,  0.77572697,  0.69261581])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1  0.3  0.5  0.7  0.9  1.1]\n"
     ]
    }
   ],
   "source": [
    "alphas = np.arange(0.1, 1.3, 0.2);\n",
    "weights=[1]\n",
    "print alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-d45f4ade94b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mskf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mscores_skf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0msss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedShuffleSplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m   1359\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m                                               fit_params)\n\u001b[1;32m-> 1361\u001b[1;33m                       for train, test in cv)\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    657\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpre_dispatch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"all\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch\u001b[1;34m(self, func, args, kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m         \"\"\"\n\u001b[0;32m    405\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_verbosity_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, args, kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[0;32m   1457\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1458\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1459\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1461\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/svm/classes.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m             )\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m         epsilon)\n\u001b[0m\u001b[0;32m    841\u001b[0m     \u001b[1;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m     \u001b[1;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for weight in weights:\n",
    "    print weight\n",
    "    \n",
    "    #pipeline.transformer_weights=[1.2, 1, 1.1, 1, 1]\n",
    "    \n",
    "    tfv_uni.binary=True\n",
    "    tfv_bi.binary=True\n",
    "    tfv_nnp.binary=True\n",
    "    tfv_punctuation.binary=True\n",
    "    \n",
    "    X = pipeline.fit_transform(pd_train)\n",
    "    results=[]\n",
    "    for i in alphas:\n",
    "        clf.C = i\n",
    "        #clf.class_weight='auto'\n",
    "        \n",
    "        skf = StratifiedKFold(Y, n_folds=5, indices=None, shuffle=True, random_state=None)\n",
    "        scores_skf = cross_val_score(clf, X, Y,scoring='accuracy',cv=skf, n_jobs=1)\n",
    "        \n",
    "        sss = StratifiedShuffleSplit(Y, 5, test_size=0.2, random_state=0)\n",
    "        scores_sss = cross_val_score(clf, X, Y,scoring='accuracy',cv=sss, n_jobs=1)\n",
    "\n",
    "        print (\"SLF: acc: %0.4f, std: %0.4f, SSS: acc: %0.4f, std: %0.4f, alpha: %s\" %\n",
    "               (scores_skf.mean(), scores_skf.std(), scores_sss.mean(), scores_sss.std(), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SVM\n",
    "#SLF: acc: 0.8114, std: 0.0073, SSS: acc: 0.8070, std: 0.0038, alpha: 1.2\n",
    "#SLF: acc: 0.8114, std: 0.0040, SSS: acc: 0.8073, std: 0.0033, alpha: 0.8\n",
    "#SLF: acc: 0.8120, std: 0.0078, SSS: acc: 0.8073, std: 0.0037, alpha: 0.7\n",
    "#SLF: acc: 0.8082, std: 0.0062, SSS: acc: 0.8079, std: 0.0037, alpha: 0.9 ===> 87,54527%\n",
    "\n",
    "\n",
    "#LOG\n",
    "#SLF: acc: 0.8012, std: 0.0044, SSS: acc: 0.8020, std: 0.0013, alpha: 60 ===> 86,8367%\n",
    "\n",
    "#best\n",
    "#SVM Accuracy: 0.7701 (+/- 0.0734), alpha: 1.3  ===> 88,57660% 'a','you','he','him','to','in','on' |auto|(1,2)|\n",
    "#SVM Accuracy: 0.7708 (+/- 0.0737), alpha: 1.9  ===> 88,43489%\n",
    "#SVM Accuracy: 0.7717 (+/- 0.0737), alpha: 2.4  ===> 88,39553\n",
    "#SVM Accuracy: 0.7709 (+/- 0.0764), alpha: 2.4  ===> 88,35616%\n",
    "#SVM Accuracy: 0.7663 (+/- 0.0764), alpha: 0.8  ===> 88,32467 %\n",
    "\n",
    "#best log Accuracy: 0.7683 (+/- 0.0798), alpha: 67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8041 (+/- 0.0074), alpha: 0\n",
      "Accuracy: 0.8063 (+/- 0.0063), alpha: 1\n",
      "Accuracy: 0.8014 (+/- 0.0109), alpha: 2\n",
      "Accuracy: 0.8072 (+/- 0.0055), alpha: 3\n",
      "Accuracy: 0.8028 (+/- 0.0027), alpha: 4\n",
      "Accuracy: 0.8050 (+/- 0.0111), alpha: 5\n",
      "Accuracy: 0.8062 (+/- 0.0031), alpha: 6\n",
      "Accuracy: 0.8063 (+/- 0.0072), alpha: 7\n",
      "Accuracy: 0.8079 (+/- 0.0094), alpha: 8\n",
      "Accuracy: 0.8033 (+/- 0.0060), alpha: 9\n",
      "['austen' 'doyle' 'poe' 'shakespeare' 'twain' 'wilde']\n",
      "[[8766  550   41   97  332  666]\n",
      " [ 424 4105   93   96  372  506]\n",
      " [   0    1   31    0    0    0]\n",
      " [  24   16   11 1828   91   34]\n",
      " [ 192  423   36  138 5008  292]\n",
      " [ 466  413   17   62  258 3336]]\n",
      "Accuracy: 0.8051 (+/- 0.0060)\n"
     ]
    }
   ],
   "source": [
    "clf.C = 0.5\n",
    "\n",
    "l = []\n",
    "for i in range(10):\n",
    "\n",
    "    scores=[]\n",
    "    confusion_mat = np.zeros([6,6],dtype=int)\n",
    "    for cv in range(5):\n",
    "        x_train, x_val, y_train, y_val = train_test_split(X,Y, test_size=0.2)\n",
    "        \n",
    "        clf.fit(x_train,y_train)\n",
    "        \n",
    "        scores.append(clf.score(x_val,y_val))\n",
    "        confusion_mat+=confusion_matrix(clf.predict(x_val),y_val)\n",
    "    l.append(np.mean(scores))\n",
    "    print (\"Accuracy: %0.4f (+/- %0.4f), alpha: %s\" % (np.mean(scores), np.std(scores) * 2, i))\n",
    "    \n",
    "print clf.classes_\n",
    "print confusion_mat\n",
    "print (\"Accuracy: %0.4f (+/- %0.4f)\" % (np.mean(l), np.std(scores) * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Boosting SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dico_pattern={'match_lowercase_only':'\\\\b[a-z]+\\\\b',\n",
    "              'match_word':'\\\\w{1,}',\n",
    "              'match_word1': '(?u)\\\\b\\\\w+\\\\b',\n",
    "              'match_word_punct': '\\w+|[,.?!;]',\n",
    "              'match_NNP': '\\\\b[A-Z][a-z]+\\\\b|\\\\b[A-Z]+\\\\b',\n",
    "              'match_punct': \"[,.?!;'-]\"\n",
    "             }\n",
    "tfv = TfidfVectorizer(lowercase=False, stop_words=None, token_pattern=dico_pattern[\"match_word_punct\"], \n",
    "                      ngram_range=(1, 2), max_df=1.0, min_df=2, max_features=None, \n",
    "                      vocabulary=None, binary=True, norm=u'l2', \n",
    "                      use_idf=True, smooth_idf=True, sublinear_tf=True)\n",
    "\n",
    "clf = LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001,\n",
    "          C=1.0, multi_class='ovr', fit_intercept=True,\n",
    "          intercept_scaling=1, class_weight=None, verbose=0,\n",
    "          random_state=None, max_iter=1000)\n",
    "\n",
    "pipeline = make_pipeline(ColumnSelector(key='Sentence'), tfv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28723, 70877)\n"
     ]
    }
   ],
   "source": [
    "Y = pd_train['Author'].values\n",
    "X = pipeline.fit_transform(pd_train) ; print X.shape\n",
    "X_test = pipeline.transform(pd_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fitting first svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd_pred = pd.DataFrame.from_csv(\"/home/arda/Documents/DSG/results/8924579.csv\", sep=\";\", index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = pd_pred['Pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### New dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41425, 105641)\n"
     ]
    }
   ],
   "source": [
    "Y = np.hstack((pd_train['Author'],y_pred))\n",
    "X = pipeline.fit_transform(pd.concat([pd_train,pd_test]))\n",
    "X_test = pipeline.transform(pd_test)\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\n"
     ]
    }
   ],
   "source": [
    "alphas = np.arange(0.1, 1.2, 0.2)\n",
    "alphas=[10]\n",
    "print alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLF: acc: 0.8519, std: 0.0059, SSS: acc: 0.8492, std: 0.0031, alpha: 10\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "for i in alphas:\n",
    "    clf.C = i\n",
    "    \n",
    "    skf = StratifiedKFold(Y, n_folds=10, indices=None, shuffle=True, random_state=None)\n",
    "    scores_skf = cross_val_score(clf, X, Y,scoring='accuracy',cv=skf, n_jobs=-1)\n",
    "\n",
    "    sss = StratifiedShuffleSplit(Y, 10, test_size=0.2, random_state=0)\n",
    "    scores_sss = cross_val_score(clf, X, Y,scoring='accuracy',cv=sss, n_jobs=-1)\n",
    "\n",
    "    print (\"SLF: acc: %0.4f, std: %0.4f, SSS: acc: %0.4f, std: %0.4f, alpha: %s\" %\n",
    "           (scores_skf.mean(), scores_skf.std(), scores_sss.mean(), scores_sss.std(), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.C = .5\n",
    "clf.fit(X,Y)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Kaggle submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['wilde', 'doyle', 'austen', ..., 'doyle', 'twain', 'wilde'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(index=None)\n",
    "submit['Id']=pd_test['Id']\n",
    "submit['Pred']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit.to_csv(folder+'/results/0.arda1.csv',sep=';',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['wilde', 'doyle', 'austen', ..., 'doyle', 'twain', 'wilde'], dtype=object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
