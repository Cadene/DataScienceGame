{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building model based on Stochastique Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arda/Documents/DSG\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.stats import randint\n",
    "\n",
    "#feature extraction modules\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.cross_validation import cross_val_score, train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import StandardScaler, scale\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "#confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "folder = os.getcwd() ; print folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### importing munged data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd_train = pd.io.pickle.read_pickle(folder + '/data_munged/pd_train_tagged')\n",
    "#pd_test = pd.io.pickle.read_pickle(folder + '/data_munged/pd_test_tagged')\n",
    "\n",
    "pd_train = pd.io.pickle.read_pickle(folder + '/data_munged/pd_train_munged')\n",
    "pd_test = pd.io.pickle.read_pickle(folder + '/data_munged/pd_test_munged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd_train['Sentence1'] = pd_train.apply(lambda x:str(x['Sentence'])+' '+str(int(x['nb_caps_word']))+' '+\n",
    "                                  str(int(x['nb_!']))+' '+str(int(x['nb_,;'])),axis=1)\n",
    "\n",
    "pd_train['Sentence2'] = pd_train.apply(lambda x:str(x['Sentence'])+' '+str(int(x['nb_caps_char']))+' '+\n",
    "                                  str(int(x['nb_!']))+' '+str(int(x['nb_,;'])),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pd_train['Sentence2'] = pd_train['tagged'].apply(lambda x: ' '.join([' '.join((word,tag)) for (word,tag) in x if len(tag)>1 ]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28723, 107402)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2507: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "list_pattern = ['\\\\w{1,}','(?u)\\\\b\\\\w+\\\\b']\n",
    "\n",
    "\n",
    "stop = None\n",
    "count = CountVectorizer(lowercase=False, stop_words=stop, token_pattern=list_pattern[1],\n",
    "                        ngram_range=(1, 3), analyzer=u'word',max_df=1., min_df=2, \n",
    "                        max_features=None, vocabulary=None, binary=False)\n",
    "\n",
    "tfidf = TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=True)\n",
    "\n",
    "#SVD = TruncatedSVD(n_components=400, algorithm='randomized', n_iter=5, random_state=None, tol=0.0)\n",
    "\n",
    "StdScl = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key].values\n",
    "\n",
    "transormData = Pipeline([\n",
    "        ('selector', ColumnSelector(key='Sentence_stemmed')),\n",
    "        ('count', count),\n",
    "        ('tfidf', tfidf),\n",
    "        #('SVD', SVD),\n",
    "        #('StdScl', StdScl)\n",
    "    ])\n",
    "\n",
    "Y = pd_train['Author']\n",
    "X = transormData.fit_transform(pd_train,Y) ; print X.shape\n",
    "X_test = transormData.transform(pd_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1e-07, 5e-07, 1e-06, 5e-06, 1e-05, 5e-05]\n"
     ]
    }
   ],
   "source": [
    "alphas = np.arange(1e-6,  50e-6, 5e-6)\n",
    "#alphas = np.arange(1e-6,  50e-6, 5e-6)\n",
    "alphas = [1e-7, 5e-7, 1e-6, 5e-6, 1e-5, 5e-5]\n",
    "#alphas = 10.**-np.arange(1,8)\n",
    "#alphas = np.arange(4e-6, 7e-6, 1e-6)\n",
    "#alphas = [1e-6]\n",
    "print alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alphas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6302dc93bb85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0malphas\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;31m#sklearn cross validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'alphas' is not defined"
     ]
    }
   ],
   "source": [
    "SGD = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-2, l1_ratio=0.15,\n",
    "                    fit_intercept=True, n_iter=50, shuffle=True, verbose=0, epsilon=0.1,\n",
    "                    n_jobs=-1, random_state=None, learning_rate='optimal', eta0=0.0,\n",
    "                    power_t=0.5, class_weight='auto', warm_start=False, average=False)\n",
    "\n",
    "results=[]\n",
    "for i in alphas:\n",
    "    #sklearn cross validation\n",
    "  \n",
    "    SGD.alpha = i\n",
    "    #NB= MultinomialNB(alpha=i, fit_prior=True, class_prior=None)\n",
    "    #scores = cross_val_score(CalibratedClassifierCV(SGD,method='sigmoid', cv=3), X,Y,scoring='accuracy',cv=5, n_jobs=-1)\n",
    "    scores = cross_val_score(SGD, X,Y,scoring='accuracy',cv=5, n_jobs=1)\n",
    "\n",
    "    print (\"Accuracy: %0.4f (+/- %0.4f), alpha: %s\" % (scores.mean(), scores.std() * 2, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Accuracy: 0.7609 (+/- 0.0664), alpha: 1e-05\n",
    "#Accuracy: 0.7662 (+/- 0.0684), alpha: 7e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7994 (+/- 0.0037), alpha: 0\n",
      "Accuracy: 0.8000 (+/- 0.0033), alpha: 1\n",
      "Accuracy: 0.7983 (+/- 0.0099), alpha: 2\n",
      "Accuracy: 0.7981 (+/- 0.0079), alpha: 3\n",
      "Accuracy: 0.8019 (+/- 0.0077), alpha: 4\n",
      "['austen' 'doyle' 'poe' 'shakespeare' 'twain' 'wilde']\n",
      "[[8591  439   28   63  276  554]\n",
      " [ 441 4085  115   78  333  446]\n",
      " [   6    6   44    1    6    0]\n",
      " [ 125   84    9 1833  152   60]\n",
      " [ 236  425   19   83 5053  331]\n",
      " [ 547  518   16   41  251 3430]]\n",
      "Accuracy: 0.7996 (+/- 0.0077)\n"
     ]
    }
   ],
   "source": [
    "SGD.alpha=1e-05\n",
    "l = []\n",
    "for i in range(5):\n",
    "    scores=[]\n",
    "    confusion_mat = np.zeros([6,6],dtype=int)\n",
    "    for cv in range(5):\n",
    "        x_train, x_val, y_train, y_val = train_test_split(X,Y, test_size=0.2, random_state=np.random.randint(1000))\n",
    "        \n",
    "        #clf =CalibratedClassifierCV(SGD,method='sigmoid', cv=3)\n",
    "        clf =SGD\n",
    "        \n",
    "        clf.fit(x_train,y_train)\n",
    "\n",
    "        \n",
    "        scores.append(clf.score(x_val,y_val))\n",
    "        confusion_mat+=confusion_matrix(clf.predict(x_val),y_val)\n",
    "    l.append(np.mean(scores))\n",
    "    print (\"Accuracy: %0.4f (+/- %0.4f), alpha: %s\" % (np.mean(scores), np.std(scores) * 2, i))\n",
    "    \n",
    "print clf.classes_\n",
    "print confusion_mat\n",
    "print (\"Accuracy: %0.4f (+/- %0.4f)\" % (np.mean(l), np.std(scores) * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen' 'doyle' 'poe' 'shakespeare' 'twain' 'wilde']\n"
     ]
    }
   ],
   "source": [
    "clf = SGDClassifier(loss='log', penalty='l2', alpha=7e-06, l1_ratio=0.15,\n",
    "                    fit_intercept=True, n_iter=20, shuffle=True, verbose=0, epsilon=0.1,\n",
    "                    n_jobs=1, random_state=None, learning_rate='optimal', eta0=0.0,\n",
    "                    power_t=0.5, class_weight='auto', warm_start=True, average=False)\n",
    "clf.fit(X,Y)\n",
    "\n",
    "classes = clf.classes_ ; print classes\n",
    "\n",
    "\n",
    "\n",
    "features = np.asarray(count.get_feature_names())\n",
    "results = pd.DataFrame({\n",
    "        'austen': clf.coef_[0,:],\n",
    "        'doyle': clf.coef_[1,:],\n",
    "        'poe': clf.coef_[2,:],\n",
    "        'shakespeare': clf.coef_[3,:],\n",
    "        'twain': clf.coef_[4,:],\n",
    "        'wilde': clf.coef_[5,:],\n",
    "        'feature': features\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results['mean'] = results[['austen', 'doyle', 'poe', 'shakespeare', 'twain', 'wilde']].apply(lambda r: np.mean(r), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# randomized GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd_train['Sentence1'] = pd_train.apply(lambda x:str(x['Sentence'])+' '+str(int(x['nb_caps_word']))+' '+\n",
    "                                  str(int(x['nb_!']))+' '+str(int(x['nb_,;'])),axis=1)\n",
    "\n",
    "pd_train['Sentence2'] = pd_train.apply(lambda x:str(x['Sentence'])+' '+str(int(x['nb_caps_char']))+' '+\n",
    "                                  str(int(x['nb_!']))+' '+str(int(x['nb_,;'])),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1728 candidates, totalling 3456 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 jobs       | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 200 jobs       | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 450 jobs       | elapsed: 22.7min\n",
      "[Parallel(n_jobs=-1)]: Done 800 jobs       | elapsed: 40.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1250 jobs       | elapsed: 63.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1800 jobs       | elapsed: 92.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2450 jobs       | elapsed: 125.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3200 jobs       | elapsed: 164.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3450 out of 3456 | elapsed: 177.7min remaining:   18.5s\n",
      "[Parallel(n_jobs=-1)]: Done 3456 out of 3456 | elapsed: 177.9min finished\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2507: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2507: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2507: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2507: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2507: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "list_pattern = ['\\\\w{1,}','(?u)\\\\b\\\\w+\\\\b']\n",
    "stop = None\n",
    "count = CountVectorizer(lowercase=False, stop_words=stop, token_pattern=list_pattern[1],\n",
    "                        ngram_range=(1, 2), analyzer=u'word',max_df=1.0, min_df=2, \n",
    "                        max_features=None, vocabulary=None, binary=False)\n",
    "tfidf = TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=True)\n",
    "\n",
    "clf = SGDClassifier(loss='hinge', penalty='l2', alpha=7e-06, l1_ratio=0.15,\n",
    "                    fit_intercept=True, n_iter=20, shuffle=True, verbose=0, epsilon=0.1,\n",
    "                    n_jobs=1, random_state=None, learning_rate='optimal', eta0=0.0,\n",
    "                    power_t=0.5, class_weight='auto', warm_start=True, average=False)\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key].values\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('column', ColumnSelector(key='Sentence1')),\n",
    "    ('vect', count),\n",
    "    ('tfidf', tfidf),\n",
    "    ('clf', clf),\n",
    "])\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "parameters = {'column__key': ('Sentence1','Sentence2'),\n",
    "              'vect__max_df': (1.0, 0.2),\n",
    "              'vect__min_df': (1, 2),\n",
    "              'vect__ngram_range': ((1, 2),(1, 3), (1, 4)),  # unigrams or bigrams\n",
    "              \n",
    "              'tfidf__use_idf': (True,),\n",
    "              'tfidf__smooth_idf': (False,),\n",
    "              'tfidf__sublinear_tf': (False,),\n",
    "              'tfidf__norm': ('l2',),\n",
    "              \n",
    "              \"clf__loss\": ('hinge', 'log'),\n",
    "              \"clf__alpha\": (1e-4, 1e-5, 5e-5, 1e-6, 5e-6, 1e-7),\n",
    "              \"clf__class_weight\": ('auto', None),\n",
    "              \"clf__penalty\": ('l1','l2','elasticnet')}\n",
    "\n",
    "\n",
    "# run randomized search\n",
    "grid = GridSearchCV(pipeline, parameters, scoring='accuracy', \n",
    "                   fit_params=None, n_jobs=-1, iid=True,\n",
    "                   refit=True,cv=2, verbose=1)\n",
    "\n",
    "\n",
    "grid.fit(pd_train,pd_train['Author'])\n",
    "\n",
    "pd.DataFrame(grid.grid_scores_, columns=['params','score','cv']).to_pickle(folder +\"/data/SGDhingelog_grid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(grid.grid_scores_, columns=['params','score','cv']).sort('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ {'vect__ngram_range': (1, 2), 'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': False, 'vect__max_df': 0.2, 'clf__loss': 'hinge', 'tfidf__use_idf': True, 'vect__min_df': 1, 'tfidf__norm': 'l2', 'clf__penalty': 'l2', 'clf__class_weight': 'auto', 'column__key': 'Sentence1', 'clf__alpha': 1e-05},\n",
       "        0.6880548689203774, array([ 0.69456242,  0.68154596])],\n",
       "       [ {'vect__ngram_range': (1, 2), 'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': False, 'vect__max_df': 0.2, 'clf__loss': 'hinge', 'tfidf__use_idf': True, 'vect__min_df': 1, 'tfidf__norm': 'l2', 'clf__penalty': 'l2', 'clf__class_weight': None, 'column__key': 'Sentence1', 'clf__alpha': 5e-05},\n",
       "        0.6875674546530655, array([ 0.69498016,  0.6801532 ])],\n",
       "       [ {'vect__ngram_range': (1, 2), 'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': False, 'vect__max_df': 0.2, 'clf__loss': 'hinge', 'tfidf__use_idf': True, 'vect__min_df': 1, 'tfidf__norm': 'l2', 'clf__penalty': 'l2', 'clf__class_weight': 'auto', 'column__key': 'Sentence1', 'clf__alpha': 5e-06},\n",
       "        0.6873585628242175, array([ 0.69184711,  0.68286908])],\n",
       "       [ {'vect__ngram_range': (1, 2), 'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': False, 'vect__max_df': 0.2, 'clf__loss': 'hinge', 'tfidf__use_idf': True, 'vect__min_df': 1, 'tfidf__norm': 'l2', 'clf__penalty': 'l2', 'clf__class_weight': 'auto', 'column__key': 'Sentence2', 'clf__alpha': 5e-06},\n",
       "        0.6871148556905615, array([ 0.69142937,  0.68279944])],\n",
       "       [ {'vect__ngram_range': (1, 3), 'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': False, 'vect__max_df': 0.2, 'clf__loss': 'hinge', 'tfidf__use_idf': True, 'vect__min_df': 1, 'tfidf__norm': 'l2', 'clf__penalty': 'l2', 'clf__class_weight': 'auto', 'column__key': 'Sentence1', 'clf__alpha': 5e-06},\n",
       "        0.6868363332520976, array([ 0.696303  ,  0.67736769])],\n",
       "       [ {'vect__ngram_range': (1, 2), 'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': False, 'vect__max_df': 0.2, 'clf__loss': 'hinge', 'tfidf__use_idf': True, 'vect__min_df': 1, 'tfidf__norm': 'l2', 'clf__penalty': 'l2', 'clf__class_weight': None, 'column__key': 'Sentence2', 'clf__alpha': 5e-05},\n",
       "        0.6867318873376737, array([ 0.69463204,  0.67883008])],\n",
       "       [ {'vect__ngram_range': (1, 2), 'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': False, 'vect__max_df': 1.0, 'clf__loss': 'hinge', 'tfidf__use_idf': True, 'vect__min_df': 1, 'tfidf__norm': 'l2', 'clf__penalty': 'l2', 'clf__class_weight': None, 'column__key': 'Sentence2', 'clf__alpha': 5e-05},\n",
       "        0.6865926261184416, array([ 0.69532827,  0.67785515])],\n",
       "       [ {'vect__ngram_range': (1, 2), 'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': False, 'vect__max_df': 1.0, 'clf__loss': 'hinge', 'tfidf__use_idf': True, 'vect__min_df': 1, 'tfidf__norm': 'l2', 'clf__penalty': 'l2', 'clf__class_weight': 'auto', 'column__key': 'Sentence2', 'clf__alpha': 5e-06},\n",
       "        0.6863837342895936, array([ 0.69059389,  0.6821727 ])],\n",
       "       [ {'vect__ngram_range': (1, 3), 'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': False, 'vect__max_df': 0.2, 'clf__loss': 'hinge', 'tfidf__use_idf': True, 'vect__min_df': 1, 'tfidf__norm': 'l2', 'clf__penalty': 'l2', 'clf__class_weight': 'auto', 'column__key': 'Sentence1', 'clf__alpha': 1e-05},\n",
       "        0.6861400271559378, array([ 0.69616375,  0.67611421])],\n",
       "       [ {'vect__ngram_range': (1, 2), 'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': False, 'vect__max_df': 1.0, 'clf__loss': 'hinge', 'tfidf__use_idf': True, 'vect__min_df': 1, 'tfidf__norm': 'l2', 'clf__penalty': 'l2', 'clf__class_weight': 'auto', 'column__key': 'Sentence2', 'clf__alpha': 1e-05},\n",
       "        0.6860703965463217, array([ 0.69240409,  0.67973538])],\n",
       "       [ {'vect__ngram_range': (1, 2), 'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': False, 'vect__max_df': 1.0, 'clf__loss': 'hinge', 'tfidf__use_idf': True, 'vect__min_df': 1, 'tfidf__norm': 'l2', 'clf__penalty': 'l2', 'clf__class_weight': None, 'column__key': 'Sentence1', 'clf__alpha': 5e-05},\n",
       "        0.6858963200222818, array([ 0.69477129,  0.6770195 ])],\n",
       "       [ {'vect__ngram_range': (1, 2), 'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': False, 'vect__max_df': 0.2, 'clf__loss': 'hinge', 'tfidf__use_idf': True, 'vect__min_df': 1, 'tfidf__norm': 'l2', 'clf__penalty': 'elasticnet', 'clf__class_weight': 'auto', 'column__key': 'Sentence2', 'clf__alpha': 5e-06},\n",
       "        0.6857918741078578, array([ 0.68906217,  0.68252089])],\n",
       "       [ {'vect__ngram_range': (1, 2), 'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': False, 'vect__max_df': 0.2, 'clf__loss': 'hinge', 'tfidf__use_idf': True, 'vect__min_df': 1, 'tfidf__norm': 'l2', 'clf__penalty': 'l2', 'clf__class_weight': None, 'column__key': 'Sentence1', 'clf__alpha': 1e-05},\n",
       "        0.6855133516693939, array([ 0.6912205 ,  0.67980501])],\n",
       "       [ {'vect__ngram_range': (1, 2), 'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': False, 'vect__max_df': 1.0, 'clf__loss': 'hinge', 'tfidf__use_idf': True, 'vect__min_df': 1, 'tfidf__norm': 'l2', 'clf__penalty': 'l2', 'clf__class_weight': 'auto', 'column__key': 'Sentence1', 'clf__alpha': 5e-06},\n",
       "        0.6853392751453539, array([ 0.69017615,  0.68050139])],\n",
       "       [ {'vect__ngram_range': (1, 3), 'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': False, 'vect__max_df': 1.0, 'clf__loss': 'hinge', 'tfidf__use_idf': True, 'vect__min_df': 2, 'tfidf__norm': 'l2', 'clf__penalty': 'l2', 'clf__class_weight': None, 'column__key': 'Sentence2', 'clf__alpha': 5e-05},\n",
       "        0.6853044598405459, array([ 0.69142937,  0.67917827])],\n",
       "       [ {'vect__ngram_range': (1, 2), 'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': False, 'vect__max_df': 0.2, 'clf__loss': 'log', 'tfidf__use_idf': True, 'vect__min_df': 1, 'tfidf__norm': 'l2', 'clf__penalty': 'elasticnet', 'clf__class_weight': 'auto', 'column__key': 'Sentence2', 'clf__alpha': 1e-06},\n",
       "        0.685200013926122, array([ 0.69428392,  0.67611421])],\n",
       "       [ {'vect__ngram_range': (1, 2), 'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': False, 'vect__max_df': 1.0, 'clf__loss': 'log', 'tfidf__use_idf': True, 'vect__min_df': 1, 'tfidf__norm': 'l2', 'clf__penalty': 'l2', 'clf__class_weight': 'auto', 'column__key': 'Sentence2', 'clf__alpha': 1e-06},\n",
       "        0.685200013926122, array([ 0.69484091,  0.6755571 ])],\n",
       "       [ {'vect__ngram_range': (1, 2), 'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': False, 'vect__max_df': 1.0, 'clf__loss': 'hinge', 'tfidf__use_idf': True, 'vect__min_df': 1, 'tfidf__norm': 'l2', 'clf__penalty': 'elasticnet', 'clf__class_weight': 'auto', 'column__key': 'Sentence2', 'clf__alpha': 5e-06},\n",
       "        0.6850955680116979, array([ 0.68801782,  0.6821727 ])],\n",
       "       [ {'vect__ngram_range': (1, 2), 'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': False, 'vect__max_df': 0.2, 'clf__loss': 'hinge', 'tfidf__use_idf': True, 'vect__min_df': 1, 'tfidf__norm': 'l2', 'clf__penalty': 'l2', 'clf__class_weight': None, 'column__key': 'Sentence2', 'clf__alpha': 1e-05},\n",
       "        0.684956306792466, array([ 0.69017615,  0.67973538])],\n",
       "       [ {'vect__ngram_range': (1, 2), 'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': False, 'vect__max_df': 0.2, 'clf__loss': 'hinge', 'tfidf__use_idf': True, 'vect__min_df': 1, 'tfidf__norm': 'l2', 'clf__penalty': 'elasticnet', 'clf__class_weight': 'auto', 'column__key': 'Sentence1', 'clf__alpha': 5e-06},\n",
       "        0.684921491487658, array([ 0.68850519,  0.68133705])]], dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.values[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(index=None)\n",
    "submit['Id']=pd_test['Id']\n",
    "submit['Pred']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit.to_csv(folder+'/results/0.arda1.csv',sep=';',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
