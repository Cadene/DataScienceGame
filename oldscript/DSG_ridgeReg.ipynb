{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arda/Documents/DSG\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#feature extraction modules\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD, SparsePCA, PCA\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, RidgeClassifierCV\n",
    "from sklearn.cross_validation import cross_val_score, train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "folder = os.getcwd() ; print folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd_train = pd.io.pickle.read_pickle(folder + '/data_munged/pd_train_tagged')\n",
    "#pd_test = pd.io.pickle.read_pickle(folder + '/data_munged/pd_test_tagged')\n",
    "\n",
    "pd_train = pd.io.pickle.read_pickle(folder + '/data_munged/pd_train_munged')\n",
    "pd_test = pd.io.pickle.read_pickle(folder + '/data_munged/pd_test_munged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd_train['Sentence1'] = pd_train.apply(lambda x:str(x['Sentence'])+' '+str(int(x['nb_caps_word']))+' '+\n",
    "                                  str(int(x['nb_!']))+' '+str(int(x['nb_,;'])),axis=1)\n",
    "\n",
    "pd_train['Sentence2'] = pd_train.apply(lambda x:str(x['Sentence'])+' '+str(int(x['nb_caps_char']))+' '+\n",
    "                                  str(int(x['nb_!']))+' '+str(int(x['nb_,;'])),axis=1)\n",
    "\n",
    "pd_test['Sentence1'] = pd_test.apply(lambda x:str(x['Sentence'])+' '+str(int(x['nb_caps_word']))+' '+\n",
    "                                  str(int(x['nb_!']))+' '+str(int(x['nb_,;'])),axis=1)\n",
    "\n",
    "pd_test['Sentence2'] = pd_test.apply(lambda x:str(x['Sentence'])+' '+str(int(x['nb_caps_char']))+' '+\n",
    "                                  str(int(x['nb_!']))+' '+str(int(x['nb_,;'])),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_pattern = ['\\\\w{1,}','(?u)\\\\b\\\\w+\\\\b']\n",
    "count = CountVectorizer(lowercase=False, stop_words=None, token_pattern=list_pattern[0],\n",
    "                        ngram_range=(1, 2), analyzer=u'word',max_df=1.0, min_df=2, \n",
    "                        max_features=None,vocabulary=None, binary=False)\n",
    "\n",
    "tfidf = TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=True)\n",
    "\n",
    "StdScl = StandardScaler(copy=True, with_mean=False, with_std=False)\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28723, 63447)\n"
     ]
    }
   ],
   "source": [
    "transormData = Pipeline([\n",
    "        ('selector', ColumnSelector(key='Sentence_stemmed')),\n",
    "        ('count', count),\n",
    "        ('tfid' , tfidf),\n",
    "        #('StdScl' , StdScl)\n",
    "    ])\n",
    "\n",
    "Y = pd_train['Author']\n",
    "X = transormData.fit_transform(pd_train,Y) ; print X.shape\n",
    "X_test = transormData.transform(pd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9]\n",
      "Accuracy: 0.7323 (+/- 0.0704), alpha: 0.1\n",
      "Accuracy: 0.7451 (+/- 0.0698), alpha: 0.2\n",
      "Accuracy: 0.7524 (+/- 0.0679), alpha: 0.3\n",
      "Accuracy: 0.7553 (+/- 0.0691), alpha: 0.4\n",
      "Accuracy: 0.7578 (+/- 0.0711), alpha: 0.5\n",
      "Accuracy: 0.7593 (+/- 0.0734), alpha: 0.6\n",
      "Accuracy: 0.7594 (+/- 0.0740), alpha: 0.7\n",
      "Accuracy: 0.7604 (+/- 0.0744), alpha: 0.8\n",
      "Accuracy: 0.7605 (+/- 0.0752), alpha: 0.9\n"
     ]
    }
   ],
   "source": [
    "params = np.arange(1, 4, 0.2 ) ; \n",
    "#params = [50,60, 70, 80, 90, 100,]\n",
    "#params = [60]\n",
    "params = np.arange(0.1, 1, 0.1 ) ; \n",
    "print params\n",
    "\n",
    "results=[]\n",
    "for i in params:\n",
    "    #sklearn cross validation\n",
    "    ridge = RidgeClassifier(alpha=i, fit_intercept=True, normalize=False, copy_X=False,\n",
    "                max_iter=None, tol=0.001, class_weight=None, solver='sparse_cg')\n",
    "    \n",
    "    clf = ridge\n",
    "\n",
    "    scores = cross_val_score(clf, X,Y,scoring='accuracy',cv=5, n_jobs=1)\n",
    "    \n",
    "    print (\"Accuracy: %0.4f (+/- %0.4f), alpha: %s\" % (scores.mean(), scores.std() * 2, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#best ridge Accuracy: 0.7606 (+/- 0.0687), alpha: 0.6 = 86,6084\n",
    "#OR\n",
    "#Accuracy: 0.7644 (+/- 0.0745), alpha: 0.6 == 86,86034%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8010 (+/- 1.6021), alpha: 0\n",
      "Accuracy: 0.7997 (+/- 1.5994), alpha: 1\n",
      "['austen' 'doyle' 'poe' 'shakespeare' 'twain' 'wilde']\n",
      "[[9048  701   46  156  403  878]\n",
      " [ 320 4035  122   96  389  453]\n",
      " [   0    0   35    0    2    0]\n",
      " [  14   11    3 1762   83   28]\n",
      " [ 172  436   30  112 5037  329]\n",
      " [ 347  368   17   51  186 3055]]\n"
     ]
    }
   ],
   "source": [
    "alpha = .6\n",
    "for i in range(2):\n",
    "    ridge = RidgeClassifier(alpha=alpha, fit_intercept=True, normalize=False, copy_X=False,\n",
    "                max_iter=None, tol=0.001, class_weight=None, solver='sparse_cg')\n",
    "       \n",
    "    clf = ridge\n",
    "\n",
    "    scores=[]\n",
    "    confusion_mat = np.zeros([6,6],dtype=int)\n",
    "    for cv in range(5):\n",
    "        x_train, x_val, y_train, y_val = train_test_split(X,Y, test_size=0.2)\n",
    "        \n",
    "        clf.fit(x_train,y_train)\n",
    "        \n",
    "        scores.append(clf.score(x_val,y_val))\n",
    "        confusion_mat+=confusion_matrix(clf.predict(x_val),y_val)\n",
    "\n",
    "    print (\"Accuracy: %0.4f (+/- %0.4f), alpha: %s\" % (np.mean(scores), np.mean(scores) * 2, i))\n",
    "    \n",
    "print clf.classes_\n",
    "print confusion_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBMIT KAGGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.fit(X,Y)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(index=None)\n",
    "submit['Id']=pd_test['Id']\n",
    "submit['Pred']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit.to_csv(folder+'/results/0.arda1.csv',sep=';',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
